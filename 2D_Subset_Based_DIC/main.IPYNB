{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some libraries\n",
    "import dic\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load image set from directory\n",
    "image_set = dic.LoadImages()\n",
    "\n",
    "#load settings from text file\n",
    "settings = dic.LoadSettings(image_set)\n",
    "\n",
    "#no of images in directory\n",
    "N_images = len(image_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign reference and deformed image objects\n",
    "F = dic.ReferenceImage(cv.imread(\"images/{}\".format(image_set[0]),0), settings)\n",
    "G = dic.DeformedImage(cv.imread(\"images/{}\".format(image_set[1]),0), settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only two images in correlation set\n",
    "G.sub_centres[0,:] = F.sub_centres[0,:] + np.round(F.P[0,:])\n",
    "G.sub_centres[1,:] = F.sub_centres[1,:] + np.round(F.P[3,:])\n",
    "\n",
    "#initial estimate of the shape function parameters as rigid body translation\n",
    "G.P[0,:], G.P[3,:] = dic.EstimateDisplacementsFourier(F, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ed\\Documents\\GitHub\\run-dic\\2D_Subset_Based_DIC\\dic.py:595: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  w_dP = np.array([\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ed\\Documents\\GitHub\\run-dic\\2D_Subset_Based_DIC\\main.IPYNB Cell 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m deformed_subset \u001b[39m=\u001b[39m dic\u001b[39m.\u001b[39mAffineTrans(G,i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#extract subset from interpolated G\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m g, g_mean, g_tilde \u001b[39m=\u001b[39m dic\u001b[39m.\u001b[39;49mDefSubsetInfo(G, deformed_subset, i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m stop_val \u001b[39m=\u001b[39m dic\u001b[39m.\u001b[39mStopCriteria(deltaP, \u001b[39m0.5\u001b[39m\u001b[39m*\u001b[39m(G\u001b[39m.\u001b[39msub_size\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m stop_val \u001b[39m<\u001b[39m \u001b[39m1e-4\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ed/Documents/GitHub/run-dic/2D_Subset_Based_DIC/main.IPYNB#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m#Zero-Mean Normalised Cross Correlation Criteria\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ed\\Documents\\GitHub\\run-dic\\2D_Subset_Based_DIC\\dic.py:555\u001b[0m, in \u001b[0;36mDefSubsetInfo\u001b[1;34m(G, deformed_subset, i)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[39m# for m in range(0,N_points):\u001b[39;00m\n\u001b[0;32m    553\u001b[0m \u001b[39m#     g[m] = G.G_interpolated(np.array([Y[m],X[m]]))\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,N_points):\n\u001b[1;32m--> 555\u001b[0m     g[m] \u001b[39m=\u001b[39m G\u001b[39m.\u001b[39mG_interpolated(Y[m],X[m])\n\u001b[0;32m    557\u001b[0m \u001b[39m#determine average intensity value of subset g,\u001b[39;00m\n\u001b[0;32m    558\u001b[0m \u001b[39m# and normalised sum of squared differences of subset, g_tilde\u001b[39;00m\n\u001b[0;32m    559\u001b[0m g_mean \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mmean()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#no of subsets for correlation run\n",
    "N_subsets = F.sub_centres.shape[1]\n",
    "\n",
    "#correlate all subsets\n",
    "for i in range(0,N_subsets):\n",
    "    f, f_mean, f_tilde, dfdx, dfdy  = dic.RefSubsetInfo(F,i)\n",
    "    #\n",
    "    Hess, fgrad_X_dWdP = dic.Hessian(dfdx, dfdy, F)\n",
    "    #\n",
    "    deltaP =  np.ones([6,1])\n",
    "    itera = 0\n",
    "    while itera < 100:\n",
    "        #deform square subset with linear transformation based on current estimation of warp function parameters (u   ux  uy  v   vx  vy)\n",
    "        deformed_subset = dic.AffineTrans(G,i)\n",
    "        #extract subset from interpolated G\n",
    "        g, g_mean, g_tilde = dic.DefSubsetInfo(G, deformed_subset, i)\n",
    "        stop_val = dic.StopCriteria(deltaP, 0.5*(G.sub_size-1))\n",
    "        if stop_val < 1e-4:\n",
    "            #Zero-Mean Normalised Cross Correlation Criteria\n",
    "            corr_coeff = 1 - sum(((f[:]-f_mean)/f_tilde-(g[:]-g_mean)/g_tilde)**2)/2\n",
    "            G.stop_val[0,i] = stop_val\n",
    "            G.iterations[0,i]  = itera\n",
    "            break \n",
    "        else:\n",
    "            Jacobian = np.dot(fgrad_X_dWdP.T, (f[:]-f_mean-f_tilde/g_tilde*(g[:]-g_mean)))\n",
    "            deltaP = np.linalg.solve(-Hess, Jacobian) #-1*np.linalg.inv(Hess)*Jacobian.T\n",
    "            Pupdate = dic.UpdateSFP(G.P[:,i], deltaP)\n",
    "            G.P[:,i:i+1] = Pupdate\n",
    "        itera = itera + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results to txt csv file\n",
    "\n",
    "np.savetxt(\"corr_results6.csv\", G.P, \n",
    "            delimiter = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('envtest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10da45e53b418cff61ea600499b3885d3466e2bef20d4502682e8e5aab9c2ee7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
